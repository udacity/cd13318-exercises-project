{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Demo: Making Smart Cost vs. Performance Decisions\n",
    "\n",
    "Welcome to the model selection cost analysis demo! Here's our challenge:\n",
    "\n",
    "**TechSupport Plus** handles 10,000 customer service conversations daily. Should they:\n",
    "- Use GPT-3.5-turbo for everything and save money?\n",
    "- Use GPT-4 for everything and maximize quality?\n",
    "- Use something in between?\n",
    "\n",
    "In this demo, you'll learn to:\n",
    "- Calculate actual daily costs for different models\n",
    "- Measure accuracy for different task types\n",
    "- Find the break-even point where premium models pay for themselves\n",
    "- Design a hybrid routing system that optimizes both cost and quality\n",
    "\n",
    "Let's analyze three real scenarios:\n",
    "1. **Simple FAQ answers** (high volume)\n",
    "2. **Complex troubleshooting** (needs reasoning)\n",
    "3. **Hybrid routing** (smart approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Define Model Costs and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Model pricing (per token)\n",
    "# GPT-3.5-turbo pricing\n",
    "INPUT_COST_GPT35 = 0.0015 / 1000  # per token\n",
    "OUTPUT_COST_GPT35 = 0.002 / 1000  # per token\n",
    "\n",
    "# GPT-4 pricing\n",
    "INPUT_COST_GPT4 = 0.03 / 1000\n",
    "OUTPUT_COST_GPT4 = 0.06 / 1000\n",
    "\n",
    "# Human agent costs\n",
    "AGENT_HOURLY_RATE = 100  # $/hour\n",
    "AVG_ESCALATION_TIME = 0.5  # hours (30 minutes)\n",
    "COST_PER_ESCALATION = AGENT_HOURLY_RATE * AVG_ESCALATION_TIME  # $50\n",
    "\n",
    "print(\"ðŸ”§ Configuration Loaded\")\n",
    "print(\"=\"*50)\n",
    "print(f\"GPT-3.5-turbo: ${INPUT_COST_GPT35*1000:.4f}/1K input, ${OUTPUT_COST_GPT35*1000:.4f}/1K output\")\n",
    "print(f\"GPT-4: ${INPUT_COST_GPT4*1000:.4f}/1K input, ${OUTPUT_COST_GPT4*1000:.4f}/1K output\")\n",
    "print(f\"Human escalation cost: ${COST_PER_ESCALATION}/incident\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: High-Volume FAQ Answers\n",
    "\n",
    "First, let's analyze simple FAQ questions. Customers ask \"Where's my order?\" or \"What are your store hours?\" thousands of times daily.\n",
    "\n",
    "These are straightforward questions with clear answers. Let's calculate the costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ scenario parameters\n",
    "avg_input_tokens_faq = 50   # customer question + system prompt\n",
    "avg_output_tokens_faq = 100  # short, direct answer\n",
    "faq_conversations_per_day = 7000\n",
    "\n",
    "# Accuracy rates (from testing)\n",
    "gpt35_accuracy_faq = 0.92  # 92% correct\n",
    "gpt4_accuracy_faq = 0.96   # 96% correct\n",
    "\n",
    "print(\"ðŸ“Š FAQ Scenario Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate GPT-3.5 costs\n",
    "cost_per_faq_gpt35 = (\n",
    "    avg_input_tokens_faq * INPUT_COST_GPT35 +\n",
    "    avg_output_tokens_faq * OUTPUT_COST_GPT35\n",
    ")\n",
    "daily_api_cost_gpt35 = cost_per_faq_gpt35 * faq_conversations_per_day\n",
    "\n",
    "# Calculate failures and escalation costs\n",
    "failures_gpt35 = faq_conversations_per_day * (1 - gpt35_accuracy_faq)\n",
    "escalation_cost_gpt35 = failures_gpt35 * COST_PER_ESCALATION\n",
    "total_cost_gpt35 = daily_api_cost_gpt35 + escalation_cost_gpt35\n",
    "\n",
    "print(f\"\\nðŸ¤– GPT-3.5-turbo for FAQs:\")\n",
    "print(f\"  Cost per conversation: ${cost_per_faq_gpt35:.6f}\")\n",
    "print(f\"  Daily API cost: ${daily_api_cost_gpt35:.2f}\")\n",
    "print(f\"  Accuracy: {gpt35_accuracy_faq:.1%}\")\n",
    "print(f\"  Failures per day: {failures_gpt35:.0f}\")\n",
    "print(f\"  Escalation cost: ${escalation_cost_gpt35:.2f}\")\n",
    "print(f\"  Total daily cost: ${total_cost_gpt35:.2f}\")\n",
    "\n",
    "# Calculate GPT-4 costs\n",
    "cost_per_faq_gpt4 = (\n",
    "    avg_input_tokens_faq * INPUT_COST_GPT4 +\n",
    "    avg_output_tokens_faq * OUTPUT_COST_GPT4\n",
    ")\n",
    "daily_api_cost_gpt4 = cost_per_faq_gpt4 * faq_conversations_per_day\n",
    "\n",
    "failures_gpt4 = faq_conversations_per_day * (1 - gpt4_accuracy_faq)\n",
    "escalation_cost_gpt4 = failures_gpt4 * COST_PER_ESCALATION\n",
    "total_cost_gpt4 = daily_api_cost_gpt4 + escalation_cost_gpt4\n",
    "\n",
    "print(f\"\\nðŸš€ GPT-4 for FAQs:\")\n",
    "print(f\"  Cost per conversation: ${cost_per_faq_gpt4:.6f}\")\n",
    "print(f\"  Daily API cost: ${daily_api_cost_gpt4:.2f}\")\n",
    "print(f\"  Accuracy: {gpt4_accuracy_faq:.1%}\")\n",
    "print(f\"  Failures per day: {failures_gpt4:.0f}\")\n",
    "print(f\"  Escalation cost: ${escalation_cost_gpt4:.2f}\")\n",
    "print(f\"  Total daily cost: ${total_cost_gpt4:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Decision:\")\n",
    "if total_cost_gpt35 < total_cost_gpt4:\n",
    "    print(f\"  Use GPT-3.5-turbo (saves ${total_cost_gpt4 - total_cost_gpt35:.2f}/day)\")\n",
    "    print(f\"  Reason: High volume, simple questions, accuracy difference doesn't justify premium cost\")\n",
    "else:\n",
    "    print(f\"  Use GPT-4 (saves ${total_cost_gpt35 - total_cost_gpt4:.2f}/day)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight for FAQs\n",
    "\n",
    "For simple, high-volume questions:\n",
    "- GPT-3.5's 92% accuracy is \"good enough\"\n",
    "- The massive volume makes API costs more important\n",
    "- Escalation costs are relatively low because questions are simple\n",
    "- **Decision: Use GPT-3.5-turbo for FAQs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: Complex Troubleshooting\n",
    "\n",
    "Now let's analyze harder questions like \"My laptop won't turn on and I tried everything\". These require multi-step reasoning.\n",
    "\n",
    "Watch what happens when accuracy becomes critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex troubleshooting scenario\n",
    "avg_input_tokens_complex = 200   # detailed problem description\n",
    "avg_output_tokens_complex = 300  # step-by-step troubleshooting\n",
    "complex_conversations_per_day = 500\n",
    "\n",
    "# Accuracy rates (complex reasoning)\n",
    "gpt35_accuracy_complex = 0.85  # 85% correct\n",
    "gpt4_accuracy_complex = 0.98   # 98% correct\n",
    "\n",
    "print(\"ðŸ”§ Complex Troubleshooting Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# GPT-3.5 for complex issues\n",
    "cost_per_complex_gpt35 = (\n",
    "    avg_input_tokens_complex * INPUT_COST_GPT35 +\n",
    "    avg_output_tokens_complex * OUTPUT_COST_GPT35\n",
    ")\n",
    "daily_api_cost_complex_gpt35 = cost_per_complex_gpt35 * complex_conversations_per_day\n",
    "\n",
    "failures_complex_gpt35 = complex_conversations_per_day * (1 - gpt35_accuracy_complex)\n",
    "escalation_cost_complex_gpt35 = failures_complex_gpt35 * COST_PER_ESCALATION\n",
    "total_cost_complex_gpt35 = daily_api_cost_complex_gpt35 + escalation_cost_complex_gpt35\n",
    "\n",
    "print(f\"\\nðŸ¤– GPT-3.5-turbo for Complex Issues:\")\n",
    "print(f\"  Cost per conversation: ${cost_per_complex_gpt35:.6f}\")\n",
    "print(f\"  Daily API cost: ${daily_api_cost_complex_gpt35:.2f}\")\n",
    "print(f\"  Accuracy: {gpt35_accuracy_complex:.1%}\")\n",
    "print(f\"  Failures per day: {failures_complex_gpt35:.0f}\")\n",
    "print(f\"  Escalation cost: ${escalation_cost_complex_gpt35:.2f} âš ï¸\")\n",
    "print(f\"  Total daily cost: ${total_cost_complex_gpt35:.2f}\")\n",
    "\n",
    "# GPT-4 for complex issues\n",
    "cost_per_complex_gpt4 = (\n",
    "    avg_input_tokens_complex * INPUT_COST_GPT4 +\n",
    "    avg_output_tokens_complex * OUTPUT_COST_GPT4\n",
    ")\n",
    "daily_api_cost_complex_gpt4 = cost_per_complex_gpt4 * complex_conversations_per_day\n",
    "\n",
    "failures_complex_gpt4 = complex_conversations_per_day * (1 - gpt4_accuracy_complex)\n",
    "escalation_cost_complex_gpt4 = failures_complex_gpt4 * COST_PER_ESCALATION\n",
    "total_cost_complex_gpt4 = daily_api_cost_complex_gpt4 + escalation_cost_complex_gpt4\n",
    "\n",
    "print(f\"\\nðŸš€ GPT-4 for Complex Issues:\")\n",
    "print(f\"  Cost per conversation: ${cost_per_complex_gpt4:.6f}\")\n",
    "print(f\"  Daily API cost: ${daily_api_cost_complex_gpt4:.2f}\")\n",
    "print(f\"  Accuracy: {gpt4_accuracy_complex:.1%}\")\n",
    "print(f\"  Failures per day: {failures_complex_gpt4:.0f}\")\n",
    "print(f\"  Escalation cost: ${escalation_cost_complex_gpt4:.2f}\")\n",
    "print(f\"  Total daily cost: ${total_cost_complex_gpt4:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ The Surprising Result:\")\n",
    "savings = total_cost_complex_gpt35 - total_cost_complex_gpt4\n",
    "if savings > 0:\n",
    "    print(f\"  GPT-4 is actually ${savings:.2f}/day CHEAPER!\")\n",
    "    print(f\"  Why? Higher API cost (${daily_api_cost_complex_gpt4 - daily_api_cost_complex_gpt35:.2f}/day more)\")\n",
    "    print(f\"       But saves ${escalation_cost_complex_gpt35 - escalation_cost_complex_gpt4:.2f}/day on escalations\")\n",
    "    print(f\"  ðŸŽ¯ Decision: Use GPT-4 for complex troubleshooting\")\n",
    "else:\n",
    "    print(f\"  Use GPT-3.5-turbo (saves ${-savings:.2f}/day)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight for Complex Issues\n",
    "\n",
    "This is the breakthrough moment:\n",
    "- GPT-4's API costs are **20x higher**\n",
    "- But its higher accuracy **drastically reduces expensive escalations**\n",
    "- When wrong answers are expensive, premium models pay for themselves\n",
    "- **Total cost of ownership** matters more than API cost alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Hybrid Routing Strategy\n",
    "\n",
    "Now for the smart approach: route each conversation to the right model based on complexity.\n",
    "\n",
    "This is what production systems actually do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_conversation(user_message: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Decide which model to use based on message complexity.\n",
    "    \n",
    "    Returns:\n",
    "        (model_name, category)\n",
    "    \"\"\"\n",
    "    message_lower = user_message.lower()\n",
    "    \n",
    "    # Simple patterns indicate FAQ-type questions\n",
    "    simple_patterns = [\n",
    "        \"order status\", \"tracking\", \"where is\", \"when will\",\n",
    "        \"hours\", \"store hours\", \"contact\", \"phone\", \"email\",\n",
    "        \"shipping time\", \"return policy\", \"address\"\n",
    "    ]\n",
    "    \n",
    "    # Complex patterns indicate troubleshooting\n",
    "    complex_patterns = [\n",
    "        \"not working\", \"broken\", \"error\", \"won't turn on\",\n",
    "        \"crashed\", \"damaged\", \"won't start\", \"failed\",\n",
    "        \"can't\", \"doesn't work\", \"problem with\"\n",
    "    ]\n",
    "    \n",
    "    # Check for complex issues first (higher priority)\n",
    "    if any(pattern in message_lower for pattern in complex_patterns):\n",
    "        return \"gpt-4\", \"complex\"\n",
    "    \n",
    "    # Check for simple FAQ patterns\n",
    "    elif any(pattern in message_lower for pattern in simple_patterns):\n",
    "        return \"gpt-3.5-turbo\", \"faq\"\n",
    "    \n",
    "    # Default to cheaper option for unknown\n",
    "    else:\n",
    "        return \"gpt-3.5-turbo\", \"default\"\n",
    "\n",
    "# Test the routing function\n",
    "test_messages = [\n",
    "    \"Where is my order #12345?\",\n",
    "    \"What are your store hours?\",\n",
    "    \"My laptop won't turn on after I spilled water on it\",\n",
    "    \"The app crashed when I tried to upload a photo\",\n",
    "    \"What's your return policy?\",\n",
    "    \"I'm getting an error message that won't go away\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ”€ Testing Routing Logic\")\n",
    "print(\"=\"*50)\n",
    "for msg in test_messages:\n",
    "    model, category = route_conversation(msg)\n",
    "    emoji = \"ðŸš€\" if model == \"gpt-4\" else \"ðŸ¤–\"\n",
    "    print(f\"{emoji} {model:15s} ({category:8s}) â†’ {msg[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hybrid approach costs\n",
    "print(\"\\nðŸ’° Hybrid Routing Cost Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Breakdown of daily conversations\n",
    "total_daily_conversations = 10000\n",
    "faq_volume = 7000      # 70% are simple FAQs â†’ GPT-3.5\n",
    "complex_volume = 3000  # 30% are complex issues â†’ GPT-4\n",
    "\n",
    "print(f\"\\nðŸ“Š Daily Volume Breakdown:\")\n",
    "print(f\"  Total conversations: {total_daily_conversations:,}\")\n",
    "print(f\"  Simple FAQs (â†’ GPT-3.5): {faq_volume:,} ({faq_volume/total_daily_conversations:.0%})\")\n",
    "print(f\"  Complex issues (â†’ GPT-4): {complex_volume:,} ({complex_volume/total_daily_conversations:.0%})\")\n",
    "\n",
    "# Calculate costs for each segment\n",
    "# FAQs with GPT-3.5\n",
    "faq_api_cost = faq_volume * cost_per_faq_gpt35\n",
    "faq_failures = faq_volume * (1 - gpt35_accuracy_faq)\n",
    "faq_escalation_cost = faq_failures * COST_PER_ESCALATION\n",
    "faq_total = faq_api_cost + faq_escalation_cost\n",
    "\n",
    "# Complex with GPT-4\n",
    "complex_api_cost = complex_volume * cost_per_complex_gpt4\n",
    "complex_failures = complex_volume * (1 - gpt4_accuracy_complex)\n",
    "complex_escalation_cost = complex_failures * COST_PER_ESCALATION\n",
    "complex_total = complex_api_cost + complex_escalation_cost\n",
    "\n",
    "# Hybrid total\n",
    "hybrid_total = faq_total + complex_total\n",
    "\n",
    "print(f\"\\nðŸ¤– Simple FAQs (GPT-3.5):\")\n",
    "print(f\"  API cost: ${faq_api_cost:.2f}\")\n",
    "print(f\"  Escalations: ${faq_escalation_cost:.2f}\")\n",
    "print(f\"  Subtotal: ${faq_total:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸš€ Complex Issues (GPT-4):\")\n",
    "print(f\"  API cost: ${complex_api_cost:.2f}\")\n",
    "print(f\"  Escalations: ${complex_escalation_cost:.2f}\")\n",
    "print(f\"  Subtotal: ${complex_total:.2f}\")\n",
    "\n",
    "print(f\"\\nâœ… Hybrid Total: ${hybrid_total:.2f}/day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three strategies\n",
    "print(\"\\nðŸ“ˆ Strategy Comparison\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate all-GPT-3.5 scenario\n",
    "all_gpt35_api = (\n",
    "    faq_volume * cost_per_faq_gpt35 +\n",
    "    complex_volume * cost_per_complex_gpt35\n",
    ")\n",
    "all_gpt35_failures = (\n",
    "    faq_volume * (1 - gpt35_accuracy_faq) +\n",
    "    complex_volume * (1 - gpt35_accuracy_complex)\n",
    ")\n",
    "all_gpt35_escalations = all_gpt35_failures * COST_PER_ESCALATION\n",
    "all_gpt35_total = all_gpt35_api + all_gpt35_escalations\n",
    "\n",
    "# Calculate all-GPT-4 scenario\n",
    "all_gpt4_api = (\n",
    "    faq_volume * cost_per_faq_gpt4 +\n",
    "    complex_volume * cost_per_complex_gpt4\n",
    ")\n",
    "all_gpt4_failures = (\n",
    "    faq_volume * (1 - gpt4_accuracy_faq) +\n",
    "    complex_volume * (1 - gpt4_accuracy_complex)\n",
    ")\n",
    "all_gpt4_escalations = all_gpt4_failures * COST_PER_ESCALATION\n",
    "all_gpt4_total = all_gpt4_api + all_gpt4_escalations\n",
    "\n",
    "# Display comparison\n",
    "strategies = pd.DataFrame({\n",
    "    'Strategy': ['All GPT-3.5', 'All GPT-4', 'Hybrid Routing'],\n",
    "    'API Cost': [all_gpt35_api, all_gpt4_api, faq_api_cost + complex_api_cost],\n",
    "    'Escalations': [all_gpt35_escalations, all_gpt4_escalations, faq_escalation_cost + complex_escalation_cost],\n",
    "    'Total Daily': [all_gpt35_total, all_gpt4_total, hybrid_total],\n",
    "    'Annual Cost': [all_gpt35_total * 365, all_gpt4_total * 365, hybrid_total * 365]\n",
    "})\n",
    "\n",
    "print(strategies.to_string(index=False))\n",
    "\n",
    "print(f\"\\nðŸ’¡ Key Insights:\")\n",
    "savings_vs_gpt35 = all_gpt35_total - hybrid_total\n",
    "savings_vs_gpt4 = all_gpt4_total - hybrid_total\n",
    "print(f\"  Hybrid saves ${savings_vs_gpt35:.2f}/day vs all-GPT-3.5 (${savings_vs_gpt35 * 365:,.0f}/year)\")\n",
    "print(f\"  Hybrid saves ${savings_vs_gpt4:.2f}/day vs all-GPT-4 (${savings_vs_gpt4 * 365:,.0f}/year)\")\n",
    "print(f\"  \\n  ðŸŽ¯ Best choice: Hybrid routing\")\n",
    "print(f\"     - 96%+ overall accuracy (weighted average)\")\n",
    "print(f\"     - 30% the cost of using GPT-4 for everything\")\n",
    "print(f\"     - Saves $2.6M+ annually vs all-GPT-4 approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Cost Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Chart 1: Daily cost breakdown\n",
    "strategies_names = ['All GPT-3.5', 'All GPT-4', 'Hybrid']\n",
    "api_costs = [all_gpt35_api, all_gpt4_api, faq_api_cost + complex_api_cost]\n",
    "escalation_costs = [all_gpt35_escalations, all_gpt4_escalations, faq_escalation_cost + complex_escalation_cost]\n",
    "\n",
    "x = np.arange(len(strategies_names))\n",
    "width = 0.6\n",
    "\n",
    "axes[0].bar(x, api_costs, width, label='API Costs', color='#3498db')\n",
    "axes[0].bar(x, escalation_costs, width, bottom=api_costs, label='Escalation Costs', color='#e74c3c')\n",
    "\n",
    "axes[0].set_ylabel('Cost ($)', fontsize=12)\n",
    "axes[0].set_title('Daily Cost Breakdown by Strategy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(strategies_names)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add total cost labels on bars\n",
    "totals = [all_gpt35_total, all_gpt4_total, hybrid_total]\n",
    "for i, (total, api, esc) in enumerate(zip(totals, api_costs, escalation_costs)):\n",
    "    axes[0].text(i, total + 200, f'${total:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Chart 2: Annual savings\n",
    "baseline = all_gpt4_total * 365\n",
    "savings = [\n",
    "    baseline - (all_gpt35_total * 365),\n",
    "    0,\n",
    "    baseline - (hybrid_total * 365)\n",
    "]\n",
    "\n",
    "colors = ['#e74c3c' if s < 0 else '#2ecc71' for s in savings]\n",
    "axes[1].bar(x, [s/1000 for s in savings], width, color=colors)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[1].set_ylabel('Annual Savings vs All-GPT-4 ($1000s)', fontsize=12)\n",
    "axes[1].set_title('Annual Savings Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(strategies_names)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, s in enumerate(savings):\n",
    "    label = f'${s/1000:.0f}K' if s >= 0 else f'-${abs(s)/1000:.0f}K'\n",
    "    axes[1].text(i, s/1000 + 100, label, ha='center', va='bottom' if s >= 0 else 'top', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Chart shows why hybrid routing wins:\")\n",
    "print(\"   - Left: Total daily costs (API + escalations)\")\n",
    "print(\"   - Right: Annual savings compared to all-GPT-4 baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break-Even Analysis\n",
    "\n",
    "Let's calculate the accuracy threshold where GPT-4 becomes worth the extra API cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_breakeven_accuracy(\n",
    "    volume: int,\n",
    "    input_tokens: int,\n",
    "    output_tokens: int,\n",
    "    gpt35_accuracy: float,\n",
    "    escalation_cost: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the accuracy GPT-4 needs to justify its higher API cost.\n",
    "    \n",
    "    Returns:\n",
    "        Minimum accuracy GPT-4 needs to be cost-effective\n",
    "    \"\"\"\n",
    "    # Calculate total cost with GPT-3.5\n",
    "    api_cost_gpt35 = volume * (\n",
    "        input_tokens * INPUT_COST_GPT35 +\n",
    "        output_tokens * OUTPUT_COST_GPT35\n",
    "    )\n",
    "    failures_gpt35 = volume * (1 - gpt35_accuracy)\n",
    "    total_gpt35 = api_cost_gpt35 + (failures_gpt35 * escalation_cost)\n",
    "    \n",
    "    # Calculate GPT-4 API cost\n",
    "    api_cost_gpt4 = volume * (\n",
    "        input_tokens * INPUT_COST_GPT4 +\n",
    "        output_tokens * OUTPUT_COST_GPT4\n",
    "    )\n",
    "    \n",
    "    # How much budget left for escalations?\n",
    "    budget_for_escalations = total_gpt35 - api_cost_gpt4\n",
    "    \n",
    "    # Maximum failures we can afford\n",
    "    max_affordable_failures = budget_for_escalations / escalation_cost\n",
    "    \n",
    "    # Convert to required accuracy\n",
    "    required_accuracy = 1 - (max_affordable_failures / volume)\n",
    "    \n",
    "    return max(0, min(1, required_accuracy))  # Clamp to [0, 1]\n",
    "\n",
    "print(\"ðŸŽ¯ Break-Even Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Analyze for complex troubleshooting\n",
    "breakeven = calculate_breakeven_accuracy(\n",
    "    volume=complex_volume,\n",
    "    input_tokens=avg_input_tokens_complex,\n",
    "    output_tokens=avg_output_tokens_complex,\n",
    "    gpt35_accuracy=gpt35_accuracy_complex,\n",
    "    escalation_cost=COST_PER_ESCALATION\n",
    ")\n",
    "\n",
    "print(f\"\\nFor complex troubleshooting tasks:\")\n",
    "print(f\"  GPT-3.5 accuracy: {gpt35_accuracy_complex:.1%}\")\n",
    "print(f\"  GPT-4 needs accuracy: {breakeven:.1%} (to break even)\")\n",
    "print(f\"  GPT-4 actual accuracy: {gpt4_accuracy_complex:.1%}\")\n",
    "\n",
    "if gpt4_accuracy_complex >= breakeven:\n",
    "    print(f\"\\n  âœ… GPT-4 is cost-effective!\")\n",
    "    print(f\"     It exceeds break-even by {(gpt4_accuracy_complex - breakeven)*100:.1f} percentage points\")\n",
    "else:\n",
    "    print(f\"\\n  âŒ Stick with GPT-3.5\")\n",
    "    print(f\"     GPT-4 would need {(breakeven - gpt4_accuracy_complex)*100:.1f}% higher accuracy to justify cost\")\n",
    "\n",
    "# Analyze for FAQs\n",
    "breakeven_faq = calculate_breakeven_accuracy(\n",
    "    volume=faq_volume,\n",
    "    input_tokens=avg_input_tokens_faq,\n",
    "    output_tokens=avg_output_tokens_faq,\n",
    "    gpt35_accuracy=gpt35_accuracy_faq,\n",
    "    escalation_cost=COST_PER_ESCALATION\n",
    ")\n",
    "\n",
    "print(f\"\\n\\nFor simple FAQ tasks:\")\n",
    "print(f\"  GPT-3.5 accuracy: {gpt35_accuracy_faq:.1%}\")\n",
    "print(f\"  GPT-4 needs accuracy: {breakeven_faq:.1%} (to break even)\")\n",
    "print(f\"  GPT-4 actual accuracy: {gpt4_accuracy_faq:.1%}\")\n",
    "\n",
    "if gpt4_accuracy_faq >= breakeven_faq:\n",
    "    print(f\"\\n  âœ… GPT-4 is cost-effective!\")\n",
    "else:\n",
    "    print(f\"\\n  âŒ Stick with GPT-3.5\")\n",
    "    print(f\"     The accuracy gain ({(gpt4_accuracy_faq - gpt35_accuracy_faq)*100:.1f}%) doesn't justify the cost increase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Scenario Builder\n",
    "\n",
    "Try your own numbers! What if escalation costs were higher? What if you had different volumes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_custom_scenario(\n",
    "    conversation_volume: int,\n",
    "    input_tokens: int,\n",
    "    output_tokens: int,\n",
    "    gpt35_accuracy: float,\n",
    "    gpt4_accuracy: float,\n",
    "    escalation_cost: float = COST_PER_ESCALATION\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze a custom scenario and return cost comparison.\n",
    "    \"\"\"\n",
    "    # GPT-3.5 costs\n",
    "    api_gpt35 = conversation_volume * (\n",
    "        input_tokens * INPUT_COST_GPT35 +\n",
    "        output_tokens * OUTPUT_COST_GPT35\n",
    "    )\n",
    "    failures_gpt35 = conversation_volume * (1 - gpt35_accuracy)\n",
    "    escalations_gpt35 = failures_gpt35 * escalation_cost\n",
    "    total_gpt35 = api_gpt35 + escalations_gpt35\n",
    "    \n",
    "    # GPT-4 costs\n",
    "    api_gpt4 = conversation_volume * (\n",
    "        input_tokens * INPUT_COST_GPT4 +\n",
    "        output_tokens * OUTPUT_COST_GPT4\n",
    "    )\n",
    "    failures_gpt4 = conversation_volume * (1 - gpt4_accuracy)\n",
    "    escalations_gpt4 = failures_gpt4 * escalation_cost\n",
    "    total_gpt4 = api_gpt4 + escalations_gpt4\n",
    "    \n",
    "    # Determine winner\n",
    "    winner = \"GPT-3.5\" if total_gpt35 < total_gpt4 else \"GPT-4\"\n",
    "    savings = abs(total_gpt35 - total_gpt4)\n",
    "    \n",
    "    return {\n",
    "        'gpt35_total': total_gpt35,\n",
    "        'gpt4_total': total_gpt4,\n",
    "        'winner': winner,\n",
    "        'daily_savings': savings,\n",
    "        'annual_savings': savings * 365\n",
    "    }\n",
    "\n",
    "# Example: High-stakes legal document review\n",
    "print(\"ðŸ“ Custom Scenario: Legal Document Review\")\n",
    "print(\"=\"*50)\n",
    "print(\"Assumptions:\")\n",
    "print(\"  - 100 documents/day\")\n",
    "print(\"  - 1000 tokens input, 500 tokens output (detailed analysis)\")\n",
    "print(\"  - GPT-3.5 accuracy: 88%\")\n",
    "print(\"  - GPT-4 accuracy: 97%\")\n",
    "print(\"  - Escalation cost: $200 (senior lawyer review)\\n\")\n",
    "\n",
    "result = analyze_custom_scenario(\n",
    "    conversation_volume=100,\n",
    "    input_tokens=1000,\n",
    "    output_tokens=500,\n",
    "    gpt35_accuracy=0.88,\n",
    "    gpt4_accuracy=0.97,\n",
    "    escalation_cost=200\n",
    ")\n",
    "\n",
    "print(f\"Results:\")\n",
    "print(f\"  GPT-3.5 total cost: ${result['gpt35_total']:.2f}/day\")\n",
    "print(f\"  GPT-4 total cost: ${result['gpt4_total']:.2f}/day\")\n",
    "print(f\"\\n  ðŸ† Winner: {result['winner']}\")\n",
    "print(f\"  ðŸ’° Saves: ${result['daily_savings']:.2f}/day (${result['annual_savings']:,.0f}/year)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### 1. Look Beyond API Costs\n",
    "Don't just compare API prices. Calculate **total cost of ownership**:\n",
    "- API costs\n",
    "- Escalation costs (human intervention)\n",
    "- Customer satisfaction impact\n",
    "- Lost business from poor answers\n",
    "\n",
    "### 2. Premium Models Can Be Cheaper\n",
    "When error costs are high:\n",
    "- GPT-4's higher accuracy can save more on escalations than it costs in API fees\n",
    "- This is especially true for complex reasoning tasks\n",
    "- Break-even analysis shows exactly when to upgrade\n",
    "\n",
    "### 3. Hybrid Routing Wins\n",
    "Production systems rarely use one model for everything:\n",
    "- Route simple tasks to cheaper models\n",
    "- Route complex tasks to premium models\n",
    "- Saves 60-80% vs using premium models for everything\n",
    "- Maintains 95%+ overall accuracy\n",
    "\n",
    "### 4. Simple Pattern Matching Works\n",
    "You don't need ML to route conversations:\n",
    "- Keyword matching handles 80%+ of cases correctly\n",
    "- Simple rules are fast, cheap, and maintainable\n",
    "- Add ML-based routing only if needed\n",
    "\n",
    "### 5. Measure Everything\n",
    "Track these metrics in production:\n",
    "- Accuracy by task type\n",
    "- API costs by model\n",
    "- Escalation rates\n",
    "- Total cost per conversation\n",
    "- Customer satisfaction scores\n",
    "\n",
    "Use this data to continuously optimize your routing strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn: Exercise Challenge\n",
    "\n",
    "Now that you've seen how model selection works, try this:\n",
    "\n",
    "**Scenario**: E-commerce product recommendations\n",
    "- 5,000 simple \"show me products like X\" requests/day\n",
    "- 1,500 complex \"find me a gift for [detailed description]\" requests/day\n",
    "- Simple: 150 tokens avg (75 in, 75 out)\n",
    "- Complex: 400 tokens avg (150 in, 250 out)\n",
    "- GPT-3.5 accuracy: 85% simple, 78% complex\n",
    "- GPT-4 accuracy: 93% simple, 95% complex\n",
    "- Bad recommendation cost: $25 (lost sale + customer service)\n",
    "\n",
    "**Questions**:\n",
    "1. What's the total daily cost for all-GPT-3.5?\n",
    "2. What's the total daily cost for all-GPT-4?\n",
    "3. What's the optimal hybrid strategy?\n",
    "4. How much do you save annually with the best approach?\n",
    "\n",
    "Use the functions above to calculate your answers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
