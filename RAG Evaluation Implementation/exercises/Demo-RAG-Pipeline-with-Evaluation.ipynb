{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"your-key-here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision\n",
    ")\n",
    "from typing import List, Dict\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë OpenAI API key configured\n",
      "‚öôÔ∏è Configuration set!\n"
     ]
    }
   ],
   "source": [
    "# Configuration settings\n",
    "COLLECTION_NAME = \"demo_collection\"\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "CHROMA_PERSIST_DIR = \"./chroma_db\"\n",
    "OPENAI_API_KEY = None  # Set your OpenAI API key here if available\n",
    "N_RESULTS = 3\n",
    "\n",
    "# Set OpenAI API key if provided\n",
    "if os.environ['OPENAI_API_KEY']:\n",
    "    openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "    print(\"üîë OpenAI API key configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No OpenAI API key - some evaluation features will be limited\")\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration set!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded existing collection: demo_collection\n",
      "üìä Current collection size: 10 documents\n"
     ]
    }
   ],
   "source": [
    "# Initialize ChromaDB client\n",
    "client = chromadb.PersistentClient(path=CHROMA_PERSIST_DIR)\n",
    "\n",
    "# Create or get collection\n",
    "try:\n",
    "    collection = client.get_collection(COLLECTION_NAME)\n",
    "    print(f\"‚úÖ Loaded existing collection: {COLLECTION_NAME}\")\n",
    "except:\n",
    "    collection = client.create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        metadata={\"description\": \"Demo collection for RAG evaluation\"}\n",
    "    )\n",
    "    print(f\"‚úÖ Created new collection: {COLLECTION_NAME}\")\n",
    "\n",
    "print(f\"üìä Current collection size: {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading embedding model...\n",
      "‚úÖ Embedding model loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Loading embedding model...\")\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "print(\"‚úÖ Embedding model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Prepared 10 sample documents\n"
     ]
    }
   ],
   "source": [
    "# Sample documents about AI/ML\n",
    "sample_documents = [\n",
    "    \"Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines that work and react like humans.\",\n",
    "    \"Machine Learning is a subset of AI that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.\",\n",
    "    \"Deep Learning is a subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns.\",\n",
    "    \"Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret and manipulate human language.\",\n",
    "    \"Computer Vision is a field of AI that trains computers to interpret and understand the visual world from digital images or videos.\",\n",
    "    \"Reinforcement Learning is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize reward.\",\n",
    "    \"Neural Networks are computing systems inspired by biological neural networks that consist of interconnected nodes processing information.\",\n",
    "    \"Supervised Learning is a machine learning approach where algorithms learn from labeled training data to make predictions on new data.\",\n",
    "    \"Unsupervised Learning looks for patterns in datasets with no pre-existing labels and minimal human supervision.\",\n",
    "    \"Feature Engineering is the process of selecting, modifying, or creating features from raw data to improve machine learning model performance.\"\n",
    "]\n",
    "\n",
    "print(f\"üìö Prepared {len(sample_documents)} sample documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Adding documents to ChromaDB...\")\n",
    "\n",
    "# Generate embeddings for documents\n",
    "print(\"Creating embeddings...\")\n",
    "embeddings = []\n",
    "for doc in tqdm(sample_documents, desc=\"Generating embeddings\"):\n",
    "    embedding = embedding_model.encode([doc])[0].tolist()\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Create metadata\n",
    "metadatas = [{\"source\": f\"doc_{i}\", \"type\": \"ai_ml_info\"} for i in range(len(sample_documents))]\n",
    "\n",
    "# Generate IDs\n",
    "existing_count = collection.count()\n",
    "ids = [f\"doc_{existing_count + i}\" for i in range(len(sample_documents))]\n",
    "\n",
    "# Add to collection\n",
    "collection.add(\n",
    "    documents=sample_documents,\n",
    "    embeddings=embeddings,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Added {len(sample_documents)} documents to collection\")\n",
    "print(f\"üìä Total documents in collection: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing document retrieval...\n",
      "\n",
      "üìù Query: 'What is machine learning?'\n",
      "  1. [Similarity: 0.612] Machine Learning is a subset of AI that provides systems the ability to automatically learn and impr...\n",
      "  2. [Similarity: 0.401] Supervised Learning is a machine learning approach where algorithms learn from labeled training data...\n",
      "\n",
      "üìù Query: 'neural networks'\n",
      "  1. [Similarity: 0.184] Neural Networks are computing systems inspired by biological neural networks that consist of interco...\n",
      "  2. [Similarity: 0.060] Deep Learning is a subset of machine learning that uses neural networks with multiple layers to mode...\n",
      "\n",
      "üìù Query: 'computer vision applications'\n",
      "  1. [Similarity: 0.222] Computer Vision is a field of AI that trains computers to interpret and understand the visual world ...\n",
      "  2. [Similarity: -0.446] Deep Learning is a subset of machine learning that uses neural networks with multiple layers to mode...\n"
     ]
    }
   ],
   "source": [
    "def retrieve_documents(query: str, n_results: int = N_RESULTS):\n",
    "    \"\"\"Retrieve relevant documents for a query\"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode([query]).tolist()\n",
    "    \n",
    "    # Search collection\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=n_results,\n",
    "        include=['documents', 'metadatas', 'distances']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'documents': results['documents'][0],\n",
    "        'metadatas': results['metadatas'][0],\n",
    "        'distances': results['distances'][0]\n",
    "    }\n",
    "\n",
    "# Test retrieval with sample queries\n",
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"neural networks\",\n",
    "    \"computer vision applications\"\n",
    "]\n",
    "\n",
    "print(\"üîç Testing document retrieval...\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüìù Query: '{query}'\")\n",
    "    results = retrieve_documents(query, n_results=2)\n",
    "    \n",
    "    for i, (doc, metadata, distance) in enumerate(zip(\n",
    "        results['documents'], results['metadatas'], results['distances']\n",
    "    )):\n",
    "        similarity = 1 - distance\n",
    "        print(f\"  {i+1}. [Similarity: {similarity:.3f}] {doc[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Answer generation function ready!\n"
     ]
    }
   ],
   "source": [
    "def generate_answer(query: str, context_docs: List[str]) -> str:\n",
    "    \"\"\"Generate answer using retrieved context\"\"\"\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "    \n",
    "    prompt = f\"\"\"Based on the following context, answer the question clearly and concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        if OPENAI_API_KEY:\n",
    "            # Using OpenAI\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=200,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        else:\n",
    "            # Fallback answer\n",
    "            return f\"Based on the retrieved context, here's information about {query}: \" \\\n",
    "                   f\"[Using simplified answer generation - add your OpenAI API key for better responses]\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating answer: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Answer generation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Running interactive Q&A session...\n",
      "\n",
      "============================================================\n",
      "‚ùì Question: What is Artificial Intelligence?\n",
      "\n",
      "üîç Retrieved 3 relevant documents:\n",
      "  1. Artificial Intelligence (AI) is a branch of computer science that aims to create...\n",
      "  2. Machine Learning is a subset of AI that provides systems the ability to automati...\n",
      "  3. Computer Vision is a field of AI that trains computers to interpret and understa...\n",
      "\n",
      "üéØ Generated Answer:\n",
      "   Based on the retrieved context, here's information about What is Artificial Intelligence?: [Using simplified answer generation - add your OpenAI API key for better responses]\n",
      "\n",
      "============================================================\n",
      "‚ùì Question: How does Machine Learning work?\n",
      "\n",
      "üîç Retrieved 3 relevant documents:\n",
      "  1. Machine Learning is a subset of AI that provides systems the ability to automati...\n",
      "  2. Supervised Learning is a machine learning approach where algorithms learn from l...\n",
      "  3. Deep Learning is a subset of machine learning that uses neural networks with mul...\n",
      "\n",
      "üéØ Generated Answer:\n",
      "   Based on the retrieved context, here's information about How does Machine Learning work?: [Using simplified answer generation - add your OpenAI API key for better responses]\n",
      "\n",
      "============================================================\n",
      "‚ùì Question: What is the difference between supervised and unsupervised learning?\n",
      "\n",
      "üîç Retrieved 3 relevant documents:\n",
      "  1. Unsupervised Learning looks for patterns in datasets with no pre-existing labels...\n",
      "  2. Supervised Learning is a machine learning approach where algorithms learn from l...\n",
      "  3. Machine Learning is a subset of AI that provides systems the ability to automati...\n",
      "\n",
      "üéØ Generated Answer:\n",
      "   Based on the retrieved context, here's information about What is the difference between supervised and unsupervised learning?: [Using simplified answer generation - add your OpenAI API key for better responses]\n",
      "\n",
      "‚úÖ Completed 3 Q&A interactions\n"
     ]
    }
   ],
   "source": [
    "# Sample questions for testing\n",
    "sample_questions = [\n",
    "    \"What is Artificial Intelligence?\",\n",
    "    \"How does Machine Learning work?\",\n",
    "    \"What is the difference between supervised and unsupervised learning?\"\n",
    "]\n",
    "\n",
    "print(\"ü§ñ Running interactive Q&A session...\")\n",
    "\n",
    "qa_results = []\n",
    "for question in sample_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚ùì Question: {question}\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    retrieval_results = retrieve_documents(question)\n",
    "    \n",
    "    print(f\"\\nüîç Retrieved {len(retrieval_results['documents'])} relevant documents:\")\n",
    "    for i, doc in enumerate(retrieval_results['documents']):\n",
    "        print(f\"  {i+1}. {doc[:80]}...\")\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = generate_answer(question, retrieval_results['documents'])\n",
    "    \n",
    "    print(f\"\\nüéØ Generated Answer:\")\n",
    "    print(f\"   {answer}\")\n",
    "    \n",
    "    # Store for evaluation\n",
    "    qa_results.append({\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'contexts': retrieval_results['documents']\n",
    "    })\n",
    "\n",
    "print(f\"\\n‚úÖ Completed {len(qa_results)} Q&A interactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating evaluation dataset...\n",
      "‚úÖ Created evaluation dataset with 3 examples\n",
      "\n",
      "Dataset preview:\n",
      "  1. Q: What is Artificial Intelligence?...\n",
      "  2. Q: How does Machine Learning work?...\n",
      "  3. Q: What is the difference between supervised and unsu...\n"
     ]
    }
   ],
   "source": [
    "# Define ground truth answers for evaluation\n",
    "ground_truth_data = [\n",
    "    {\n",
    "        \"question\": \"What is Artificial Intelligence?\",\n",
    "        \"ground_truth\": \"Artificial Intelligence is a branch of computer science that aims to create intelligent machines that work and react like humans.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does Machine Learning work?\", \n",
    "        \"ground_truth\": \"Machine Learning provides systems the ability to automatically learn and improve from experience without being explicitly programmed.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the difference between supervised and unsupervised learning?\",\n",
    "        \"ground_truth\": \"Supervised learning uses labeled training data to make predictions, while unsupervised learning looks for patterns in data with no pre-existing labels.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üìä Creating evaluation dataset...\")\n",
    "\n",
    "# Create evaluation dataset\n",
    "eval_data = []\n",
    "for gt in ground_truth_data:\n",
    "    question = gt[\"question\"]\n",
    "    ground_truth = gt[\"ground_truth\"]\n",
    "    \n",
    "    # Get retrieval results\n",
    "    retrieval_results = retrieve_documents(question)\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = generate_answer(question, retrieval_results['documents'])\n",
    "    \n",
    "    eval_data.append({\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'contexts': retrieval_results['documents'],\n",
    "        'ground_truth': ground_truth\n",
    "    })\n",
    "\n",
    "# Convert to RAGAS dataset format\n",
    "eval_df = pd.DataFrame(eval_data)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "print(f\"‚úÖ Created evaluation dataset with {len(eval_dataset)} examples\")\n",
    "print(\"\\nDataset preview:\")\n",
    "for i, example in enumerate(eval_dataset):\n",
    "    print(f\"  {i+1}. Q: {example['question'][:50]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = evaluate(\n",
    "        dataset=eval_dataset,\n",
    "        metrics=metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Running RAGAS evaluation...\n",
      "‚è≥ This may take a few minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:05<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Evaluation Results:\n",
      "========================================\n",
      "üìä AGGREGATE METRICS:\n",
      "-------------------------\n",
      "faithfulness        : 0.333 üî¥ Needs Improvement\n",
      "answer_relevancy    : 0.000 üî¥ Needs Improvement\n",
      "context_recall      : 1.000 üü¢ Excellent\n",
      "context_precision   : 1.000 üü¢ Excellent\n",
      "\n",
      "üìã PER-RECORD RESULTS SUMMARY:\n",
      "-----------------------------------\n",
      "üìä Overall Performance Summary:\n",
      "Average Score Across All Metrics: 0.583\n",
      "üü¢ Excellent records (>0.7): 0/3\n",
      "üü° Good records (0.5-0.7): 3/3\n",
      "üî¥ Poor records (‚â§0.5): 0/3\n",
      "\n",
      "üíæ Per-record results saved to 'per_record_results' variable\n",
      "   Use per_record_results to analyze individual record performance\n"
     ]
    }
   ],
   "source": [
    "print(\"üìà Running RAGAS evaluation...\")\n",
    "\n",
    "try:\n",
    "    # Define metrics to evaluate\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision\n",
    "    ]\n",
    "    \n",
    "    print(\"‚è≥ This may take a few minutes...\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    evaluation_results = evaluate(\n",
    "        dataset=eval_dataset,\n",
    "        metrics=metrics,\n",
    "        raise_exceptions=False  # Continue evaluation even if some records fail\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ Evaluation Results:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Display aggregate metrics (overall performance)\n",
    "    print(\"üìä AGGREGATE METRICS:\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    metric_names = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']\n",
    "    aggregate_scores = {}\n",
    "    \n",
    "    for metric_name in metric_names:\n",
    "        scores = evaluation_results[metric_name]\n",
    "        # Calculate mean score across all records\n",
    "        valid_scores = [s for s in scores if s is not None and not np.isnan(s)]\n",
    "        if valid_scores:\n",
    "            avg_score = np.mean(valid_scores)\n",
    "            aggregate_scores[metric_name] = avg_score\n",
    "            \n",
    "            # Color coding for terminal output\n",
    "            if avg_score > 0.7:\n",
    "                status = \"üü¢ Excellent\"\n",
    "            elif avg_score > 0.5:\n",
    "                status = \"üü° Good\"\n",
    "            else:\n",
    "                status = \"üî¥ Needs Improvement\"\n",
    "            \n",
    "            print(f\"{metric_name:20s}: {avg_score:.3f} {status}\")\n",
    "    \n",
    "    # Create detailed per-record results\n",
    "    print(f\"\\nüìã PER-RECORD RESULTS SUMMARY:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    detailed_results = []\n",
    "    \n",
    "    for i in range(len(eval_dataset)):\n",
    "        record_result = {\n",
    "            'record_id': i,\n",
    "            'question': eval_dataset['question'][i][:100] + \"...\" if len(eval_dataset['question'][i]) > 100 else eval_dataset['question'][i]\n",
    "        }\n",
    "        \n",
    "        # Add per-record scores\n",
    "        for metric_name in metric_names:\n",
    "            if i < len(evaluation_results[metric_name]):\n",
    "                score = evaluation_results[metric_name][i]\n",
    "                record_result[metric_name] = score if score is not None else 'N/A'\n",
    "            else:\n",
    "                record_result[metric_name] = 'N/A'\n",
    "        \n",
    "        # Calculate average score per record\n",
    "        scores = [record_result[metric] for metric in metric_names if isinstance(record_result[metric], (int, float))]\n",
    "        record_result['avg_score'] = np.mean(scores) if scores else 0\n",
    "        \n",
    "        detailed_results.append(record_result)\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"üìä Overall Performance Summary:\")\n",
    "    if aggregate_scores:\n",
    "        overall_avg = np.mean(list(aggregate_scores.values()))\n",
    "        print(f\"Average Score Across All Metrics: {overall_avg:.3f}\")\n",
    "        \n",
    "        # Count records by performance level\n",
    "        excellent_count = sum(1 for r in detailed_results if r['avg_score'] > 0.7)\n",
    "        good_count = sum(1 for r in detailed_results if 0.5 < r['avg_score'] <= 0.7)\n",
    "        poor_count = sum(1 for r in detailed_results if r['avg_score'] <= 0.5)\n",
    "        \n",
    "        print(f\"üü¢ Excellent records (>0.7): {excellent_count}/{len(detailed_results)}\")\n",
    "        print(f\"üü° Good records (0.5-0.7): {good_count}/{len(detailed_results)}\")\n",
    "        print(f\"üî¥ Poor records (‚â§0.5): {poor_count}/{len(detailed_results)}\")\n",
    "    \n",
    "    # Save detailed results to variable for further analysis\n",
    "    per_record_results = detailed_results\n",
    "    print(f\"\\nüíæ Per-record results saved to 'per_record_results' variable\")\n",
    "    print(f\"   Use per_record_results to analyze individual record performance\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Evaluation Error: {e}\")\n",
    "    print(\"üí° Note: Full RAGAS evaluation requires OpenAI API access for some metrics\")\n",
    "    print(\"   Set OPENAI_API_KEY in Cell 2 to enable complete evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
