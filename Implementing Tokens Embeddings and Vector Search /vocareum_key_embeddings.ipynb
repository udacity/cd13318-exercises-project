{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demo 3: Embeddings and Semantic Search\n",
        "\n",
        "In this demo, you'll learn how embeddings transform text into numbers and enable semantic search! We'll explore:\n",
        "\n",
        "1. **What are embeddings?** - Converting text to vectors\n",
        "2. **Creating embeddings** - Using OpenAI's API\n",
        "3. **Similarity calculations** - Finding related content\n",
        "4. **Semantic search** - Finding reviews by meaning, not just keywords\n",
        "5. **Clustering** - Grouping similar items automatically\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this demo, you'll understand:\n",
        "- How embeddings capture semantic meaning in numbers\n",
        "- How to measure similarity between texts\n",
        "- How semantic search differs from keyword search\n",
        "- How to build a simple recommendation system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if needed\n",
        "# !pip install openai numpy scikit-learn matplotlib pandas\n",
        "\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Initialize OpenAI client\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=\"https://openai.vocareum.com/v1\" if api_key.startswith(\"voc\") else None\n",
        ")\n",
        "\n",
        "print(\"âœ… Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: What Are Embeddings?\n",
        "\n",
        "Embeddings are **numerical representations of text** that capture semantic meaning.\n",
        "\n",
        "Think of it this way:\n",
        "- Text: \"The movie was amazing!\" \n",
        "- Embedding: [0.234, -0.891, 0.456, ...] (1536 numbers for OpenAI's model)\n",
        "\n",
        "Similar meanings = similar numbers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "    \"\"\"Get embedding vector for a text.\"\"\"\n",
        "    text = text.replace(\"\\n\", \" \")  # Clean the text\n",
        "    response = client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=model\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# Get embeddings for sample texts\n",
        "text1 = \"I love this product!\"\n",
        "text2 = \"This is terrible quality.\"\n",
        "text3 = \"Great purchase, very happy!\"\n",
        "\n",
        "emb1 = get_embedding(text1)\n",
        "emb2 = get_embedding(text2)\n",
        "emb3 = get_embedding(text3)\n",
        "\n",
        "print(\"ðŸ“Š Embedding Details:\\n\")\n",
        "print(f\"Text: '{text1}'\")\n",
        "print(f\"Embedding length: {len(emb1)} dimensions\")\n",
        "print(f\"First 10 values: {emb1[:10]}\")\n",
        "print(f\"\\nThese {len(emb1)} numbers capture the meaning of the text!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Key Insight\n",
        "\n",
        "Embeddings are high-dimensional vectors (1536 dimensions!) where:\n",
        "- Each dimension captures some aspect of meaning\n",
        "- Similar texts have similar embedding vectors\n",
        "- You can do math with meanings! (\"king\" - \"man\" + \"woman\" â‰ˆ \"queen\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Calculating Cosine Similarity\n",
        "\n",
        "**Cosine similarity** measures how similar two embeddings are.\n",
        "\n",
        "- 1.0 = identical\n",
        "- 0.9+ = very similar\n",
        "- 0.7-0.9 = somewhat similar\n",
        "- < 0.5 = not very similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_similarity(emb1, emb2):\n",
        "    \"\"\"Calculate cosine similarity between two embeddings.\"\"\"\n",
        "    emb1 = np.array(emb1).reshape(1, -1)\n",
        "    emb2 = np.array(emb2).reshape(1, -1)\n",
        "    return cosine_similarity(emb1, emb2)[0][0]\n",
        "\n",
        "# Compare our three texts\n",
        "sim_1_2 = calculate_similarity(emb1, emb2)\n",
        "sim_1_3 = calculate_similarity(emb1, emb3)\n",
        "sim_2_3 = calculate_similarity(emb2, emb3)\n",
        "\n",
        "print(\"ðŸ” Similarity Comparison:\\n\")\n",
        "print(f\"'{text1}' vs '{text2}': {sim_1_2:.4f} (different sentiment)\")\n",
        "print(f\"'{text1}' vs '{text3}': {sim_1_3:.4f} (similar sentiment)\")\n",
        "print(f\"'{text2}' vs '{text3}': {sim_2_3:.4f} (opposite sentiment)\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Notice how positive reviews are more similar to each other!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Sample Product Reviews Dataset\n",
        "\n",
        "Let's create a realistic dataset of product reviews to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample product reviews\n",
        "reviews = [\n",
        "    {\"id\": 1, \"text\": \"This backpack is incredibly durable and has lots of storage space. Perfect for hiking!\", \"category\": \"positive\"},\n",
        "    {\"id\": 2, \"text\": \"The water bottle leaks constantly. Very disappointed with the quality.\", \"category\": \"negative\"},\n",
        "    {\"id\": 3, \"text\": \"Amazing quality! The material is waterproof and the zippers are sturdy. Highly recommend.\", \"category\": \"positive\"},\n",
        "    {\"id\": 4, \"text\": \"Terrible customer service. They never responded to my emails about the defective product.\", \"category\": \"negative\"},\n",
        "    {\"id\": 5, \"text\": \"Great value for money. The backpack exceeded my expectations for the price.\", \"category\": \"positive\"},\n",
        "    {\"id\": 6, \"text\": \"The product arrived damaged and the return process was a nightmare.\", \"category\": \"negative\"},\n",
        "    {\"id\": 7, \"text\": \"Love the design and color options. The bag is stylish and functional.\", \"category\": \"positive\"},\n",
        "    {\"id\": 8, \"text\": \"Not worth the money. Cheap materials that tore after one week of use.\", \"category\": \"negative\"},\n",
        "    {\"id\": 9, \"text\": \"Excellent for outdoor adventures! Kept all my gear dry during a rainstorm.\", \"category\": \"positive\"},\n",
        "    {\"id\": 10, \"text\": \"The straps are uncomfortable and dig into my shoulders. Poor ergonomic design.\", \"category\": \"negative\"},\n",
        "    {\"id\": 11, \"text\": \"Perfect size for day trips. Fits my laptop, water bottle, and snacks comfortably.\", \"category\": \"positive\"},\n",
        "    {\"id\": 12, \"text\": \"Zipper broke after two uses. Don't waste your money on this.\", \"category\": \"negative\"},\n",
        "    {\"id\": 13, \"text\": \"Fast shipping and great packaging. The product quality is outstanding!\", \"category\": \"positive\"},\n",
        "    {\"id\": 14, \"text\": \"Way too expensive for what you get. Similar products cost half the price.\", \"category\": \"negative\"},\n",
        "    {\"id\": 15, \"text\": \"This is my third purchase from this brand. Always reliable and high quality.\", \"category\": \"positive\"}\n",
        "]\n",
        "\n",
        "# Display reviews\n",
        "df = pd.DataFrame(reviews)\n",
        "print(\"ðŸ“ Product Reviews Dataset:\\n\")\n",
        "print(df.to_string(index=False))\n",
        "print(f\"\\nTotal reviews: {len(reviews)}\")\n",
        "print(f\"Positive: {sum(1 for r in reviews if r['category'] == 'positive')}\")\n",
        "print(f\"Negative: {sum(1 for r in reviews if r['category'] == 'negative')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Creating Embeddings for All Reviews\n",
        "\n",
        "Let's create embeddings for our entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸ”„ Creating embeddings for all reviews...\\n\")\n",
        "\n",
        "# Get embeddings for all reviews\n",
        "for review in reviews:\n",
        "    review['embedding'] = get_embedding(review['text'])\n",
        "    print(f\"âœ… Review {review['id']}: Embedded\")\n",
        "\n",
        "print(f\"\\nâœ… Created {len(reviews)} embeddings!\")\n",
        "print(f\"Each embedding has {len(reviews[0]['embedding'])} dimensions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Semantic Search - Finding Similar Reviews\n",
        "\n",
        "Now let's search for reviews by **meaning**, not just keywords!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def semantic_search(query, reviews, top_k=3):\n",
        "    \"\"\"Find the most similar reviews to a query.\"\"\"\n",
        "    # Get query embedding\n",
        "    query_embedding = get_embedding(query)\n",
        "    \n",
        "    # Calculate similarity with all reviews\n",
        "    for review in reviews:\n",
        "        review['similarity'] = calculate_similarity(query_embedding, review['embedding'])\n",
        "    \n",
        "    # Sort by similarity\n",
        "    sorted_reviews = sorted(reviews, key=lambda x: x['similarity'], reverse=True)\n",
        "    \n",
        "    return sorted_reviews[:top_k]\n",
        "\n",
        "# Example searches\n",
        "queries = [\n",
        "    \"Looking for a sturdy bag for outdoor activities\",\n",
        "    \"Had issues with product breaking quickly\",\n",
        "    \"Good deal for the price\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"ðŸ” Query: '{query}'\\n\")\n",
        "    results = semantic_search(query, reviews, top_k=3)\n",
        "    \n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"  {i}. [Similarity: {result['similarity']:.4f}] {result['text']}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Key Insight\n",
        "\n",
        "Notice how semantic search finds relevant reviews even when:\n",
        "- The exact words don't match\n",
        "- Synonyms are used (\"sturdy\" â†’ \"durable\")\n",
        "- The concept is expressed differently\n",
        "\n",
        "This is **much more powerful** than keyword search!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Visualizing Embeddings with PCA\n",
        "\n",
        "Let's reduce 1536 dimensions down to 2D so we can visualize the embeddings!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract embeddings as a matrix\n",
        "embeddings_matrix = np.array([r['embedding'] for r in reviews])\n",
        "\n",
        "# Reduce to 2D using PCA\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(embeddings_matrix)\n",
        "\n",
        "# Separate by category\n",
        "positive_indices = [i for i, r in enumerate(reviews) if r['category'] == 'positive']\n",
        "negative_indices = [i for i, r in enumerate(reviews) if r['category'] == 'negative']\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.scatter(\n",
        "    embeddings_2d[positive_indices, 0],\n",
        "    embeddings_2d[positive_indices, 1],\n",
        "    c='green',\n",
        "    marker='o',\n",
        "    s=200,\n",
        "    alpha=0.6,\n",
        "    edgecolors='darkgreen',\n",
        "    linewidths=2,\n",
        "    label='Positive Reviews'\n",
        ")\n",
        "\n",
        "plt.scatter(\n",
        "    embeddings_2d[negative_indices, 0],\n",
        "    embeddings_2d[negative_indices, 1],\n",
        "    c='red',\n",
        "    marker='s',\n",
        "    s=200,\n",
        "    alpha=0.6,\n",
        "    edgecolors='darkred',\n",
        "    linewidths=2,\n",
        "    label='Negative Reviews'\n",
        ")\n",
        "\n",
        "# Add labels for each point\n",
        "for i, review in enumerate(reviews):\n",
        "    plt.annotate(\n",
        "        f\"#{review['id']}\",\n",
        "        (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
        "        fontsize=9,\n",
        "        ha='center',\n",
        "        va='center'\n",
        "    )\n",
        "\n",
        "plt.xlabel('First Principal Component', fontsize=12)\n",
        "plt.ylabel('Second Principal Component', fontsize=12)\n",
        "plt.title('Product Reviews - Embedding Visualization (PCA)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11, loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸ“Š Notice how positive and negative reviews cluster together!\")\n",
        "print(\"Similar sentiment = similar location in the embedding space.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Clustering Reviews by Theme\n",
        "\n",
        "Let's use K-Means clustering to automatically group reviews by topic!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform clustering\n",
        "n_clusters = 3\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(embeddings_matrix)\n",
        "\n",
        "# Add cluster labels to reviews\n",
        "for i, review in enumerate(reviews):\n",
        "    review['cluster'] = cluster_labels[i]\n",
        "\n",
        "# Show clusters\n",
        "print(f\"ðŸŽ¯ Automatic Clustering into {n_clusters} Groups:\\n\")\n",
        "\n",
        "for cluster_id in range(n_clusters):\n",
        "    cluster_reviews = [r for r in reviews if r['cluster'] == cluster_id]\n",
        "    print(f\"\\nðŸ“¦ Cluster {cluster_id + 1} ({len(cluster_reviews)} reviews):\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    for review in cluster_reviews:\n",
        "        print(f\"  [{review['category'].upper()}] {review['text']}\")\n",
        "\n",
        "# Visualize clusters\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "for cluster_id in range(n_clusters):\n",
        "    cluster_indices = [i for i, r in enumerate(reviews) if r['cluster'] == cluster_id]\n",
        "    plt.scatter(\n",
        "        embeddings_2d[cluster_indices, 0],\n",
        "        embeddings_2d[cluster_indices, 1],\n",
        "        c=colors[cluster_id],\n",
        "        marker='o',\n",
        "        s=200,\n",
        "        alpha=0.6,\n",
        "        edgecolors='black',\n",
        "        linewidths=2,\n",
        "        label=f'Cluster {cluster_id + 1}'\n",
        "    )\n",
        "    \n",
        "    # Add labels\n",
        "    for i in cluster_indices:\n",
        "        plt.annotate(\n",
        "            f\"#{reviews[i]['id']}\",\n",
        "            (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
        "            fontsize=9,\n",
        "            ha='center',\n",
        "            va='center',\n",
        "            fontweight='bold'\n",
        "        )\n",
        "\n",
        "plt.xlabel('First Principal Component', fontsize=12)\n",
        "plt.ylabel('Second Principal Component', fontsize=12)\n",
        "plt.title('Product Reviews - Clustered by Similarity', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11, loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ’¡ Clusters might represent themes like: quality issues, customer service, product features, etc.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Practical Applications\n",
        "\n",
        "Let's explore real-world uses of embeddings!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸš€ Practical Applications of Embeddings:\\n\")\n",
        "\n",
        "# Application 1: FAQ Matching\n",
        "print(\"1ï¸âƒ£ FAQ Matching - Find relevant help articles\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "faq_question = \"How do I return a damaged item?\"\n",
        "related_reviews = semantic_search(faq_question, reviews, top_k=2)\n",
        "\n",
        "print(f\"Customer question: '{faq_question}'\\n\")\n",
        "print(\"Related customer experiences:\")\n",
        "for i, review in enumerate(related_reviews, 1):\n",
        "    print(f\"  {i}. {review['text']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Application 2: Duplicate Detection\n",
        "print(\"2ï¸âƒ£ Duplicate Detection - Find similar/duplicate reviews\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Pick a review and find most similar ones\n",
        "target_review = reviews[0]\n",
        "similarities = []\n",
        "\n",
        "for review in reviews:\n",
        "    if review['id'] != target_review['id']:\n",
        "        sim = calculate_similarity(target_review['embedding'], review['embedding'])\n",
        "        similarities.append((review, sim))\n",
        "\n",
        "similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(f\"Target review: '{target_review['text']}'\\n\")\n",
        "print(\"Most similar reviews (potential duplicates):\")\n",
        "for review, sim in similarities[:3]:\n",
        "    print(f\"  [Similarity: {sim:.4f}] {review['text']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Application 3: Recommendation System\n",
        "print(\"3ï¸âƒ£ Recommendation System - 'Customers who liked this also liked...'\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "user_liked_review = reviews[2]  # User liked review #3\n",
        "recommendations = semantic_search(user_liked_review['text'], reviews, top_k=4)\n",
        "recommendations = [r for r in recommendations if r['id'] != user_liked_review['id']][:3]\n",
        "\n",
        "print(f\"User liked: '{user_liked_review['text']}'\\n\")\n",
        "print(\"You might also like these products (based on similar reviews):\")\n",
        "for i, rec in enumerate(recommendations, 1):\n",
        "    print(f\"  {i}. {rec['text']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Application 4: Sentiment Analysis\n",
        "print(\"4ï¸âƒ£ Sentiment Analysis - Classify review sentiment\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create reference embeddings for positive and negative\n",
        "positive_ref = get_embedding(\"This product is amazing, high quality, and I love it!\")\n",
        "negative_ref = get_embedding(\"This product is terrible, poor quality, and I hate it!\")\n",
        "\n",
        "# Test on a new review\n",
        "new_review = \"The backpack is okay but the straps could be better\"\n",
        "new_embedding = get_embedding(new_review)\n",
        "\n",
        "pos_sim = calculate_similarity(new_embedding, positive_ref)\n",
        "neg_sim = calculate_similarity(new_embedding, negative_ref)\n",
        "\n",
        "print(f\"New review: '{new_review}'\\n\")\n",
        "print(f\"Similarity to positive reference: {pos_sim:.4f}\")\n",
        "print(f\"Similarity to negative reference: {neg_sim:.4f}\")\n",
        "print(f\"\\nPredicted sentiment: {'Positive' if pos_sim > neg_sim else 'Negative'}\")\n",
        "print(f\"Confidence: {abs(pos_sim - neg_sim):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Key Takeaways\n",
        "\n",
        "1. **Embeddings = Meaning as Numbers** - Text converted to vectors that capture semantic meaning\n",
        "\n",
        "2. **Cosine Similarity Measures Relatedness** - Higher similarity = more similar meaning\n",
        "\n",
        "3. **Semantic Search > Keyword Search** - Find content by meaning, not just matching words\n",
        "\n",
        "4. **Similar Texts Cluster Together** - Embeddings naturally group related content\n",
        "\n",
        "5. **Many Applications** - FAQ matching, duplicate detection, recommendations, sentiment analysis\n",
        "\n",
        "6. **Visualization Helps Understanding** - PCA reduces dimensions for human interpretation\n",
        "\n",
        "## ðŸ’° Cost Considerations\n",
        "\n",
        "Embedding costs (text-embedding-3-small):\n",
        "- $0.02 per 1 million tokens\n",
        "- Much cheaper than chat completions!\n",
        "- Create once, reuse many times\n",
        "\n",
        "## ðŸ’¡ Best Practices\n",
        "\n",
        "1. **Cache embeddings**: Don't recreate them every time\n",
        "2. **Batch processing**: Embed multiple texts in one API call\n",
        "3. **Choose the right model**: text-embedding-3-small vs text-embedding-3-large\n",
        "4. **Normalize your data**: Clean text before embedding\n",
        "5. **Store efficiently**: Use vector databases for large-scale applications\n",
        "\n",
        "## ðŸš€ Try It Yourself!\n",
        "\n",
        "Experiments to run:\n",
        "1. Add your own reviews and see where they cluster\n",
        "2. Try different search queries and examine the results\n",
        "3. Experiment with different numbers of clusters (K-means)\n",
        "4. Build a product recommendation system for your domain\n",
        "5. Compare keyword search vs semantic search accuracy"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
